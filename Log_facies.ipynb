{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Cr.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Db8JSj0kCLgv"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saumil-Agarwal/Aircraft_Accident-Hackerearth/blob/master/Log_facies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxsayUpQkyfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwTd51gs7MbA",
        "colab_type": "text"
      },
      "source": [
        "# Mounting and Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HEP6cBi1M9-",
        "colab_type": "code",
        "outputId": "98949f71-bfb9-46bd-f5ef-420b8818a80c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU5aMVod16lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buc5I7Fs2IY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6FadGZS2tjI",
        "colab_type": "code",
        "outputId": "b0fda542-6dcc-460d-b180-6ab7fcddc17a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "df = pd.read_csv('CAX_LogFacies_Train_File.csv')\n",
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.describe())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   row_id  well_id          GR  label\n",
            "0       0        0  143.510000      0\n",
            "1       1        0  112.790928      0\n",
            "2       2        0  123.531856      0\n",
            "3       3        0  111.692784      0\n",
            "4       4        0  123.613712      0\n",
            "(4400000, 4)\n",
            "             row_id       well_id            GR         label\n",
            "count  4.400000e+06  4.400000e+06  4.400000e+06  4.400000e+06\n",
            "mean   5.495000e+02  1.999500e+03  1.092733e+02  1.184489e+00\n",
            "std    3.175426e+02  1.154701e+03  3.424240e+01  1.465016e+00\n",
            "min    0.000000e+00  0.000000e+00 -3.181915e+00  0.000000e+00\n",
            "25%    2.747500e+02  9.997500e+02  8.179222e+01  0.000000e+00\n",
            "50%    5.495000e+02  1.999500e+03  1.203849e+02  0.000000e+00\n",
            "75%    8.242500e+02  2.999250e+03  1.347291e+02  2.000000e+00\n",
            "max    1.099000e+03  3.999000e+03  1.970614e+02  4.000000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvBMVWcdVqN3",
        "colab_type": "code",
        "outputId": "ae49986d-0c0e-4ac6-be68-1ce20c5fb66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2313281\n",
              "2     525376\n",
              "3     522140\n",
              "1     520744\n",
              "4     518459\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db8JSj0kCLgv",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc8RRaqBcxR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['GR']\n",
        "y = df['label']\n",
        "\n",
        "X_tr, X_tst, y_tr, y_tst = train_test_split(X, y, test_size=0.3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqWfNwqLc-cz",
        "colab_type": "code",
        "outputId": "aeccf0cf-f819-4aef-f73c-6d1ee3f1b641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "y_tst.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    693819\n",
              "2    157656\n",
              "3    156537\n",
              "1    156361\n",
              "4    155627\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JPleISQ-_kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.loc[0:1000000, ['GR']] \n",
        "y = df.loc[0:1000000, ['label']] \n",
        "\n",
        "X_tr, X_tst, y_tr, y_tst = train_test_split(X, y, test_size=0.15)\n",
        "\n",
        "X_tr = X_tr.values\n",
        "X_tst = X_tst.values\n",
        "\n",
        "y_tr = y_tr.values\n",
        "y_tst = y_tst.values\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "575_ZeRx9JHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "clf=RandomForestClassifier(n_estimators=100,min_samples_leaf=3)\n",
        "clf.fit(X_tr, y_tr)\n",
        "print('fit done')\n",
        "predicted= clf.predict(X_tst)\n",
        "print('prediction done')\n",
        "print(metrics.accuracy_score(y_tst, predicted))\n",
        "# print(RandomForestClassifier())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOYQ5XsjjkyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_tst, predicted))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lQfbXjTCSYj",
        "colab_type": "text"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUo9BtDlrNWR",
        "colab_type": "code",
        "outputId": "265d7d39-46f5-4432-f7a7-44391d979585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDE2Wdn4t-6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Dense, Input, SimpleRNN, LSTM\n",
        "# from keras.activation import relu\n",
        "# from keras.optimizer import adam\n",
        "from sklearn import preprocessing\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjJ80X2xgVV",
        "colab_type": "code",
        "outputId": "46915972-2389-4ed7-d213-b1c0a3c51772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df.head(1101)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>well_id</th>\n",
              "      <th>GR</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>143.510000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>112.790928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>123.531856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>111.692784</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>123.613712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1096</th>\n",
              "      <td>1096</td>\n",
              "      <td>0</td>\n",
              "      <td>158.257216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097</th>\n",
              "      <td>1097</td>\n",
              "      <td>0</td>\n",
              "      <td>139.508144</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1098</th>\n",
              "      <td>1098</td>\n",
              "      <td>0</td>\n",
              "      <td>130.589072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099</th>\n",
              "      <td>1099</td>\n",
              "      <td>0</td>\n",
              "      <td>154.930000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1100</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>122.260000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1101 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  well_id          GR  label\n",
              "0          0        0  143.510000      0\n",
              "1          1        0  112.790928      0\n",
              "2          2        0  123.531856      0\n",
              "3          3        0  111.692784      0\n",
              "4          4        0  123.613712      0\n",
              "...      ...      ...         ...    ...\n",
              "1096    1096        0  158.257216      0\n",
              "1097    1097        0  139.508144      0\n",
              "1098    1098        0  130.589072      0\n",
              "1099    1099        0  154.930000      0\n",
              "1100       0        1  122.260000      0\n",
              "\n",
              "[1101 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsR5R6Fsw3m5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = df[[GR']]\n",
        "# y = df[['label']]\n",
        "\n",
        "X = df.loc[:, ['row_id','GR']] \n",
        "y = df.loc[:, ['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6xFvB8J7SsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pd.set_option('display.max_rows', 1100)\n",
        "# np.set_printoptions(threshold=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W4Ml-RUp3tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.loc[:, ['row_id','GR']]\n",
        "X_changed = preprocessing.scale(X)  #normalizing X\n",
        "print(X_changed)\n",
        "# X_changed = X.values\n",
        "X_changed = X_changed.reshape(-1,1100,2) #changing gr as parameters\n",
        "print('Reshape')\n",
        "print(X_changed)\n",
        "print(X_changed.shape)\n",
        "\n",
        "# y_changed = y.values\n",
        "# y_changed = y_changed.reshape(-1,1100)\n",
        "# print(y_changed)\n",
        "# print(y_changed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6EFHvu9wPBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.values  #One hot encoding\n",
        "onehotencoder = preprocessing.OneHotEncoder(categories = [[0,1,2,3,4]])  #hot encoding y\n",
        "y_one_hot = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "print(y_one_hot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EQSLqp_0oGF",
        "colab_type": "code",
        "outputId": "2eb2980b-5ee6-4758-a86a-57977f7cb4dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_one_hot.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4400000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z67-nZSMAGWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_changed = y_one_hot.reshape(-1,1100,5)  # changing the outputs so that each CELL of lstm gives an output\n",
        "print(y_changed)\n",
        "print(y_changed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLpbBIRhxXlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr, X_tst, y_tr, y_tst = train_test_split(X_changed, y_changed, test_size=0.2)\n",
        "print(X_tr.shape)\n",
        "print(X_tst.shape)\n",
        "\n",
        "X_tr = np.reshape(X_tr, (X_tr.shape[0], X_tr.shape[1],1)) # reshaping the X to pass as LSTM input\n",
        "X_tst = np.reshape(X_tst, (X_tst.shape[0], X_tst.shape[1],1))\n",
        "print(X_tr.shape)\n",
        "print(X_tst.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_tst.shape)\n",
        "print(X_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzCAYAaokEf6",
        "colab_type": "text"
      },
      "source": [
        "**Implementing various Lstm variations\n",
        "These have been implemented in hardcoded fashion and not through function so that they can be run overnight on colab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzH7krAPvTW7",
        "colab_type": "text"
      },
      "source": [
        "**There was leak in dataset - repeating pattern of digits after the decimal point. Hence, the results of applied lstm weren't effective and accurate enough.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123p1zPIVlja",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3KN8TdqxbH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,2)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape))\n",
        "model.add(LSTM(units = 5, return_sequences=True,recurrent_activation='softmax'))\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Epoch 100/100 loss: nan - acc: 0.5261 without row id\n",
        "#Accuracy is: 52.41375"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHC-zm5cOjF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MydLoarGDnk",
        "colab_type": "code",
        "outputId": "aea66dfa-c469-40c1-8deb-4436c9fb3fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 100, batch_size=256)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3200/3200 [==============================] - 39s 12ms/step - loss: 4.3867 - acc: 0.1667\n",
            "Epoch 2/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 4.1517 - acc: 0.3513\n",
            "Epoch 3/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 4.8503 - acc: 0.3311\n",
            "Epoch 4/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 6.8904 - acc: 0.1344\n",
            "Epoch 5/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 5.4108 - acc: 0.1172\n",
            "Epoch 6/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 3.0524 - acc: 0.1179\n",
            "Epoch 7/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 2.8033 - acc: 0.1179\n",
            "Epoch 8/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 2.5509 - acc: 0.1178\n",
            "Epoch 9/100\n",
            "3200/3200 [==============================] - 38s 12ms/step - loss: 2.2583 - acc: 0.0961\n",
            "Epoch 10/100\n",
            " 512/3200 [===>..........................] - ETA: 30s - loss: 2.2169 - acc: 0.0937"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-94180a6e9685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#validation_data ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6ZHk_onbhJQ",
        "colab_type": "code",
        "outputId": "de560ffe-5a8d-485c-aa13-29ec21b5ca27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 1100, 5)\n",
            "880000\n",
            "880000\n",
            "Accuracy is: 52.41375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rveystccWPpJ",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43PZa9KUb8_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keras model - Thisonegoood.......\n",
        "\n",
        "batch_input_shape = (None,1100,2)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape))\n",
        "model.add(LSTM(units = 1, return_sequences=True))\n",
        "model.add(LSTM(units = 5, return_sequences=True))\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Epoch 3/100 loss: 2.6473 - acc: 0.5358  without row id\n",
        "#Epoch 100/100 loss: 1.1276 - acc: 0.0799\n",
        "#Accuracy is: 7.985681818181818"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTNo2lDzbor3",
        "colab_type": "code",
        "outputId": "4f25709b-ec98-4e58-87fc-19f75307088c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 1100, 1)           16        \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 1100, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 168\n",
            "Trainable params: 168\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCZMclqOcHkB",
        "colab_type": "code",
        "outputId": "326cbd51-eb12-4560-d637-5d68e3ddca5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 150, batch_size=128)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "3200/3200 [==============================] - 53s 17ms/step - loss: 1.5789 - acc: 0.2768\n",
            "Epoch 2/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4995 - acc: 0.3425\n",
            "Epoch 3/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.4586 - acc: 0.3404\n",
            "Epoch 4/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4895 - acc: 0.3355\n",
            "Epoch 5/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.4358 - acc: 0.3195\n",
            "Epoch 6/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.4184 - acc: 0.3203\n",
            "Epoch 7/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4055 - acc: 0.3206\n",
            "Epoch 8/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4003 - acc: 0.3309\n",
            "Epoch 9/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3908 - acc: 0.3328\n",
            "Epoch 10/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3931 - acc: 0.3375\n",
            "Epoch 11/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3917 - acc: 0.3389\n",
            "Epoch 12/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.4022 - acc: 0.3418\n",
            "Epoch 13/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3984 - acc: 0.3384\n",
            "Epoch 14/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3835 - acc: 0.3334\n",
            "Epoch 15/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3756 - acc: 0.3320\n",
            "Epoch 16/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3790 - acc: 0.3317\n",
            "Epoch 17/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3768 - acc: 0.3299\n",
            "Epoch 18/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3685 - acc: 0.3266\n",
            "Epoch 19/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3675 - acc: 0.3264\n",
            "Epoch 20/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3684 - acc: 0.3264\n",
            "Epoch 21/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3668 - acc: 0.3255\n",
            "Epoch 22/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3998 - acc: 0.3313\n",
            "Epoch 23/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4326 - acc: 0.3388\n",
            "Epoch 24/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.4042 - acc: 0.3420\n",
            "Epoch 25/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3849 - acc: 0.3435\n",
            "Epoch 26/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3745 - acc: 0.3460\n",
            "Epoch 27/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3739 - acc: 0.3504\n",
            "Epoch 28/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3718 - acc: 0.3550\n",
            "Epoch 29/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3667 - acc: 0.3564\n",
            "Epoch 30/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3841 - acc: 0.3533\n",
            "Epoch 31/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3738 - acc: 0.3511\n",
            "Epoch 32/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3669 - acc: 0.3491\n",
            "Epoch 33/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3624 - acc: 0.3471\n",
            "Epoch 34/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3593 - acc: 0.3459\n",
            "Epoch 35/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3573 - acc: 0.3435\n",
            "Epoch 36/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3573 - acc: 0.3421\n",
            "Epoch 37/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3559 - acc: 0.3427\n",
            "Epoch 38/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3541 - acc: 0.3414\n",
            "Epoch 39/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3543 - acc: 0.3425\n",
            "Epoch 40/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3529 - acc: 0.3402\n",
            "Epoch 41/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3522 - acc: 0.3391\n",
            "Epoch 42/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3536 - acc: 0.3354\n",
            "Epoch 43/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3542 - acc: 0.3328\n",
            "Epoch 44/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3511 - acc: 0.3283\n",
            "Epoch 45/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3554 - acc: 0.3299\n",
            "Epoch 46/150\n",
            "3200/3200 [==============================] - 50s 15ms/step - loss: 1.3767 - acc: 0.3315\n",
            "Epoch 47/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3906 - acc: 0.3279\n",
            "Epoch 48/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3781 - acc: 0.3267\n",
            "Epoch 49/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3733 - acc: 0.3221\n",
            "Epoch 50/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3637 - acc: 0.3202\n",
            "Epoch 51/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3617 - acc: 0.3164\n",
            "Epoch 52/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3531 - acc: 0.3104\n",
            "Epoch 53/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3732 - acc: 0.2984\n",
            "Epoch 54/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3576 - acc: 0.2959\n",
            "Epoch 55/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3666 - acc: 0.3041\n",
            "Epoch 56/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3665 - acc: 0.3124\n",
            "Epoch 57/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3553 - acc: 0.3184\n",
            "Epoch 58/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3504 - acc: 0.3190\n",
            "Epoch 59/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3472 - acc: 0.3184\n",
            "Epoch 60/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3482 - acc: 0.3199\n",
            "Epoch 61/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3486 - acc: 0.3208\n",
            "Epoch 62/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3469 - acc: 0.3201\n",
            "Epoch 63/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3482 - acc: 0.3181\n",
            "Epoch 64/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3465 - acc: 0.3181\n",
            "Epoch 65/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3459 - acc: 0.3179\n",
            "Epoch 66/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3458 - acc: 0.3177\n",
            "Epoch 67/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3463 - acc: 0.3190\n",
            "Epoch 68/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3716 - acc: 0.3087\n",
            "Epoch 69/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3930 - acc: 0.2933\n",
            "Epoch 70/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3673 - acc: 0.2969\n",
            "Epoch 71/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3539 - acc: 0.2980\n",
            "Epoch 72/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3486 - acc: 0.2908\n",
            "Epoch 73/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3471 - acc: 0.2863\n",
            "Epoch 74/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3589 - acc: 0.2889\n",
            "Epoch 75/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3720 - acc: 0.2854\n",
            "Epoch 76/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.4567 - acc: 0.2898\n",
            "Epoch 77/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4304 - acc: 0.3021\n",
            "Epoch 78/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3929 - acc: 0.3123\n",
            "Epoch 79/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3590 - acc: 0.3156\n",
            "Epoch 80/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3517 - acc: 0.3155\n",
            "Epoch 81/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3480 - acc: 0.3127\n",
            "Epoch 82/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3467 - acc: 0.3087\n",
            "Epoch 83/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3462 - acc: 0.3112\n",
            "Epoch 84/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3458 - acc: 0.3119\n",
            "Epoch 85/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3495 - acc: 0.3112\n",
            "Epoch 86/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3506 - acc: 0.3118\n",
            "Epoch 87/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3482 - acc: 0.3116\n",
            "Epoch 88/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3465 - acc: 0.3142\n",
            "Epoch 89/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3512 - acc: 0.3098\n",
            "Epoch 90/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3462 - acc: 0.3106\n",
            "Epoch 91/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3455 - acc: 0.3134\n",
            "Epoch 92/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3462 - acc: 0.3100\n",
            "Epoch 93/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3446 - acc: 0.3105\n",
            "Epoch 94/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3441 - acc: 0.3112\n",
            "Epoch 95/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3443 - acc: 0.3106\n",
            "Epoch 96/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3450 - acc: 0.3108\n",
            "Epoch 97/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3446 - acc: 0.3106\n",
            "Epoch 98/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3453 - acc: 0.3093\n",
            "Epoch 99/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3461 - acc: 0.3081\n",
            "Epoch 100/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3449 - acc: 0.3080\n",
            "Epoch 101/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3428 - acc: 0.3088\n",
            "Epoch 102/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3421 - acc: 0.3079\n",
            "Epoch 103/150\n",
            "3200/3200 [==============================] - 53s 16ms/step - loss: 1.3419 - acc: 0.3071\n",
            "Epoch 104/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3432 - acc: 0.3068\n",
            "Epoch 105/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3422 - acc: 0.3061\n",
            "Epoch 106/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3456 - acc: 0.3022\n",
            "Epoch 107/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3456 - acc: 0.3015\n",
            "Epoch 108/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3424 - acc: 0.3027\n",
            "Epoch 109/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3775 - acc: 0.3037\n",
            "Epoch 110/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.4172 - acc: 0.3056\n",
            "Epoch 111/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.4009 - acc: 0.3183\n",
            "Epoch 112/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3873 - acc: 0.3202\n",
            "Epoch 113/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3770 - acc: 0.3196\n",
            "Epoch 114/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3684 - acc: 0.3195\n",
            "Epoch 115/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3607 - acc: 0.3158\n",
            "Epoch 116/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3515 - acc: 0.3104\n",
            "Epoch 117/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3456 - acc: 0.3088\n",
            "Epoch 118/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3434 - acc: 0.3111\n",
            "Epoch 119/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3426 - acc: 0.3124\n",
            "Epoch 120/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3429 - acc: 0.3154\n",
            "Epoch 121/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3427 - acc: 0.3075\n",
            "Epoch 122/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3414 - acc: 0.3084\n",
            "Epoch 123/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3407 - acc: 0.3141\n",
            "Epoch 124/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3407 - acc: 0.3127\n",
            "Epoch 125/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3404 - acc: 0.3184\n",
            "Epoch 126/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3401 - acc: 0.3173\n",
            "Epoch 127/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3422 - acc: 0.3075\n",
            "Epoch 128/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3408 - acc: 0.3187\n",
            "Epoch 129/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3392 - acc: 0.3189\n",
            "Epoch 130/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3380 - acc: 0.3193\n",
            "Epoch 131/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3376 - acc: 0.3198\n",
            "Epoch 132/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3380 - acc: 0.3198\n",
            "Epoch 133/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3373 - acc: 0.3206\n",
            "Epoch 134/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3362 - acc: 0.3212\n",
            "Epoch 135/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3360 - acc: 0.3216\n",
            "Epoch 136/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3357 - acc: 0.3220\n",
            "Epoch 137/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3364 - acc: 0.3209\n",
            "Epoch 138/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3386 - acc: 0.3206\n",
            "Epoch 139/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3382 - acc: 0.3212\n",
            "Epoch 140/150\n",
            "3200/3200 [==============================] - 53s 16ms/step - loss: 1.3357 - acc: 0.3234\n",
            "Epoch 141/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3334 - acc: 0.3224\n",
            "Epoch 142/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3364 - acc: 0.3233\n",
            "Epoch 143/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3335 - acc: 0.3238\n",
            "Epoch 144/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3312 - acc: 0.3258\n",
            "Epoch 145/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3282 - acc: 0.3264\n",
            "Epoch 146/150\n",
            "3200/3200 [==============================] - 52s 16ms/step - loss: 1.3253 - acc: 0.3271\n",
            "Epoch 147/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3248 - acc: 0.3273\n",
            "Epoch 148/150\n",
            "3200/3200 [==============================] - 51s 16ms/step - loss: 1.3325 - acc: 0.3233\n",
            "Epoch 149/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3277 - acc: 0.3189\n",
            "Epoch 150/150\n",
            "3200/3200 [==============================] - 50s 16ms/step - loss: 1.3237 - acc: 0.3263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3553e139b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTtzDRfmy_rz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 50, batch_size=128)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxTYrpH97G_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.2,\n",
        "                              patience=5, min_lr=0.001)\n",
        "model.fit(X_train, Y_train, callbacks=[reduce_lr])\n",
        "model.fit(X_tr,y_tr, epochs= 120, batch_size=128)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERKM5B8Fbomr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR1sEwGLWVnN",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dioTpUNXboLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,2)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 5, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='sigmoid'))\n",
        "\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Epoch 100/100 loss: 1.2052 - acc: 0.1216 without row id\n",
        "#Accuracy is: 12.273068181818182"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgwCjGzCdBSa",
        "colab_type": "code",
        "outputId": "f62171c4-e364-442e-dadb-3ed8dfa3403e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_30 (LSTM)               (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 140\n",
            "Trainable params: 140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLtnJJ0tdBNV",
        "colab_type": "code",
        "outputId": "7a913b6f-aae9-4f9f-dcbf-aea79480298b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 100, batch_size=256)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3200/3200 [==============================] - 8s 3ms/step - loss: 1.8476 - acc: 0.0819\n",
            "Epoch 2/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.7626 - acc: 0.0808\n",
            "Epoch 3/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.6883 - acc: 0.0792\n",
            "Epoch 4/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.6275 - acc: 0.0777\n",
            "Epoch 5/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.5739 - acc: 0.0759\n",
            "Epoch 6/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.5253 - acc: 0.0737\n",
            "Epoch 7/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.4802 - acc: 0.0727\n",
            "Epoch 8/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.4421 - acc: 0.0732\n",
            "Epoch 9/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.4063 - acc: 0.0751\n",
            "Epoch 10/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.3627 - acc: 0.0800\n",
            "Epoch 11/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.3273 - acc: 0.0865\n",
            "Epoch 12/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.3029 - acc: 0.0928\n",
            "Epoch 13/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2869 - acc: 0.0916\n",
            "Epoch 14/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2873 - acc: 0.0843\n",
            "Epoch 15/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2931 - acc: 0.0816\n",
            "Epoch 16/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2929 - acc: 0.0805\n",
            "Epoch 17/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2891 - acc: 0.0800\n",
            "Epoch 18/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2836 - acc: 0.0808\n",
            "Epoch 19/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2812 - acc: 0.0805\n",
            "Epoch 20/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2798 - acc: 0.0799\n",
            "Epoch 21/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2774 - acc: 0.0792\n",
            "Epoch 22/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2764 - acc: 0.0785\n",
            "Epoch 23/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2760 - acc: 0.0782\n",
            "Epoch 24/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2732 - acc: 0.0777\n",
            "Epoch 25/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2693 - acc: 0.0773\n",
            "Epoch 26/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2666 - acc: 0.0773\n",
            "Epoch 27/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2639 - acc: 0.0776\n",
            "Epoch 28/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2624 - acc: 0.0784\n",
            "Epoch 29/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2630 - acc: 0.0802\n",
            "Epoch 30/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2628 - acc: 0.0817\n",
            "Epoch 31/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2584 - acc: 0.0824\n",
            "Epoch 32/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2576 - acc: 0.0842\n",
            "Epoch 33/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2625 - acc: 0.0876\n",
            "Epoch 34/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2532 - acc: 0.0884\n",
            "Epoch 35/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2403 - acc: 0.0883\n",
            "Epoch 36/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2352 - acc: 0.0890\n",
            "Epoch 37/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2327 - acc: 0.0901\n",
            "Epoch 38/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2290 - acc: 0.0906\n",
            "Epoch 39/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2319 - acc: 0.0926\n",
            "Epoch 40/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2316 - acc: 0.0954\n",
            "Epoch 41/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2268 - acc: 0.0979\n",
            "Epoch 42/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2243 - acc: 0.1013\n",
            "Epoch 43/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2198 - acc: 0.1042\n",
            "Epoch 44/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2160 - acc: 0.1069\n",
            "Epoch 45/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2119 - acc: 0.1085\n",
            "Epoch 46/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2084 - acc: 0.1110\n",
            "Epoch 47/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2074 - acc: 0.1141\n",
            "Epoch 48/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2068 - acc: 0.1195\n",
            "Epoch 49/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2060 - acc: 0.1246\n",
            "Epoch 50/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2039 - acc: 0.1295\n",
            "Epoch 51/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1992 - acc: 0.1311\n",
            "Epoch 52/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2010 - acc: 0.1376\n",
            "Epoch 53/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2024 - acc: 0.1428\n",
            "Epoch 54/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1977 - acc: 0.1404\n",
            "Epoch 55/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1951 - acc: 0.1437\n",
            "Epoch 56/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1941 - acc: 0.1478\n",
            "Epoch 57/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1931 - acc: 0.1496\n",
            "Epoch 58/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1927 - acc: 0.1509\n",
            "Epoch 59/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1959 - acc: 0.1552\n",
            "Epoch 60/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1934 - acc: 0.1569\n",
            "Epoch 61/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1929 - acc: 0.1378\n",
            "Epoch 62/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1928 - acc: 0.1284\n",
            "Epoch 63/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1878 - acc: 0.1259\n",
            "Epoch 64/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1847 - acc: 0.1248\n",
            "Epoch 65/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1819 - acc: 0.1242\n",
            "Epoch 66/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1803 - acc: 0.1239\n",
            "Epoch 67/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1787 - acc: 0.1242\n",
            "Epoch 68/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1778 - acc: 0.1248\n",
            "Epoch 69/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1809 - acc: 0.1286\n",
            "Epoch 70/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1823 - acc: 0.1307\n",
            "Epoch 71/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1808 - acc: 0.1312\n",
            "Epoch 72/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1775 - acc: 0.1309\n",
            "Epoch 73/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1750 - acc: 0.1288\n",
            "Epoch 74/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1741 - acc: 0.1276\n",
            "Epoch 75/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1727 - acc: 0.1273\n",
            "Epoch 76/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1720 - acc: 0.1273\n",
            "Epoch 77/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1719 - acc: 0.1256\n",
            "Epoch 78/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1743 - acc: 0.1233\n",
            "Epoch 79/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1733 - acc: 0.1223\n",
            "Epoch 80/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1743 - acc: 0.1220\n",
            "Epoch 81/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1736 - acc: 0.1217\n",
            "Epoch 82/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.1892 - acc: 0.1214\n",
            "Epoch 83/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2312 - acc: 0.1210\n",
            "Epoch 84/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2417 - acc: 0.1209\n",
            "Epoch 85/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2419 - acc: 0.1207\n",
            "Epoch 86/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2400 - acc: 0.1205\n",
            "Epoch 87/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2379 - acc: 0.1206\n",
            "Epoch 88/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2365 - acc: 0.1206\n",
            "Epoch 89/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2345 - acc: 0.1202\n",
            "Epoch 90/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2318 - acc: 0.1202\n",
            "Epoch 91/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2295 - acc: 0.1206\n",
            "Epoch 92/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2268 - acc: 0.1210\n",
            "Epoch 93/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2236 - acc: 0.1215\n",
            "Epoch 94/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2214 - acc: 0.1210\n",
            "Epoch 95/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2187 - acc: 0.1213\n",
            "Epoch 96/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2166 - acc: 0.1216\n",
            "Epoch 97/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2141 - acc: 0.1217\n",
            "Epoch 98/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2136 - acc: 0.1215\n",
            "Epoch 99/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2119 - acc: 0.1214\n",
            "Epoch 100/100\n",
            "3200/3200 [==============================] - 6s 2ms/step - loss: 1.2052 - acc: 0.1216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c5f31c400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkvjdlZsdA-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hayM5DgKvzuW",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixaPUYeodOuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,1)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape))\n",
        "model.add(LSTM(units = 5, return_sequences=True))\n",
        "\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Epoch 100/100 loss: nan - acc: 0.5261\n",
        "# Accuracy is: 52.41375"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLpIYHq8dRcq",
        "colab_type": "code",
        "outputId": "f546054d-cb31-4142-e22c-4d8a01b6b233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_31 (LSTM)               (None, 1100, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 152\n",
            "Trainable params: 152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3s7lBGndRVd",
        "colab_type": "code",
        "outputId": "577a6d75-9c97-420f-b6c1-79901a99fbfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 100, batch_size=256)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3200/3200 [==============================] - 15s 5ms/step - loss: 9.8114 - acc: 0.4283\n",
            "Epoch 2/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 5.5147 - acc: 0.0913\n",
            "Epoch 3/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 4.9170 - acc: 0.0661\n",
            "Epoch 4/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 4.3889 - acc: 0.1044\n",
            "Epoch 5/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 4.0774 - acc: 0.1200\n",
            "Epoch 6/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.8093 - acc: 0.1200\n",
            "Epoch 7/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.4682 - acc: 0.1200\n",
            "Epoch 8/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.2867 - acc: 0.1200\n",
            "Epoch 9/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.2600 - acc: 0.1200\n",
            "Epoch 10/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.2896 - acc: 0.1200\n",
            "Epoch 11/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.3427 - acc: 0.1200\n",
            "Epoch 12/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.3962 - acc: 0.1200\n",
            "Epoch 13/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: 3.4484 - acc: 0.1200\n",
            "Epoch 14/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.1682\n",
            "Epoch 15/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 16/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 17/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 18/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 19/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 20/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 21/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 22/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 23/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 24/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 25/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 26/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 27/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 28/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 29/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 30/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 31/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 32/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 33/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 34/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 35/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 36/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 37/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 38/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 39/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 40/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 41/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 42/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 43/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 44/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 45/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 46/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 47/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 48/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 49/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 50/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 51/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 52/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 53/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 54/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 55/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 56/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 57/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 58/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 59/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 60/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 61/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 62/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 63/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 64/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 65/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 66/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 67/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 68/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 69/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 70/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 71/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 72/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 73/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 74/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 75/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 76/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 77/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 78/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 79/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 80/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 81/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 82/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 83/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 84/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 85/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 86/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 87/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 88/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 89/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 90/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 91/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 92/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 93/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 94/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 95/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 96/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 97/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 98/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 99/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n",
            "Epoch 100/100\n",
            "3200/3200 [==============================] - 12s 4ms/step - loss: nan - acc: 0.5261\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c5dc11860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfOjwiPWdRPo",
        "colab_type": "code",
        "outputId": "d55e4ecb-1648-4cfa-b0bb-8506fd64a081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 1100, 5)\n",
            "880000\n",
            "880000\n",
            "Accuracy is: 52.41375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhmvE2M4v5r-",
        "colab_type": "text"
      },
      "source": [
        "# Adding a new feature for LSTM(difference of GR Values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip17BLfFv6rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.loc[:, ['GR']] \n",
        "y = df.loc[:, ['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBu4a4pv69g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=X.values\n",
        "print(X.shape)\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3sRdoUiwc5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = np.delete(X, (X.shape[0]-1), axis=0)\n",
        "X1 = np.insert(X1,0,np.array([0]),axis=0)\n",
        "print(X1)\n",
        "print(X1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAXJc49kyzb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X2 = X-X1\n",
        "print(X2)\n",
        "X2 = np.delete(X2, (0), axis=0)\n",
        "X2 = np.insert(X2,0,np.array([0]),axis=0)         #Here assigned the first value as the origin.Need to change it later.\n",
        "                                                  #Also for each well it should be different need tochange that too\n",
        "print(X2)\n",
        "print(X2.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ym9kw3U0GF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.loc[:, ['GR']]\n",
        "X_changed = preprocessing.scale(X2)  #normalizing X2\n",
        "# X_changed = X.values\n",
        "X_changed = X_changed.reshape(-1,1100) #changing gr as parameters\n",
        "print(X_changed)\n",
        "print(X_changed.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZumBlqS1HRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.values\n",
        "onehotencoder = preprocessing.OneHotEncoder(categories = [[0,1,2,3,4]])  #hot encoding y\n",
        "y_one_hot = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "print(y_one_hot)\n",
        "print(y_one_hot.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CezTMzXf1IO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_changed = y_one_hot.reshape(-1,1100,5)  # changing the outputs so that each CELL of lstm gives an output\n",
        "print(y_changed)\n",
        "print(y_changed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6a4IqcQ189I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_tr, X_tst, y_tr, y_tst = train_test_split(X_changed, y_changed, test_size=0.2)\n",
        "print(X_tr.shape)\n",
        "print(X_tst.shape)\n",
        "\n",
        "X_tr = np.reshape(X_tr, (X_tr.shape[0], X_tr.shape[1],1)) # reshaping the X to pass as LSTM input\n",
        "X_tst = np.reshape(X_tst, (X_tst.shape[0], X_tst.shape[1],1))\n",
        "print(X_tr.shape)\n",
        "print(X_tst.shape)\n",
        "print(y_tr.shape)\n",
        "print(y_tst.shape)\n",
        "print(X_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJIMWqpiYCYF",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-HqFkTs181f",
        "colab_type": "code",
        "outputId": "f755cff9-8040-4669-d2f7-53d4568b21a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,1)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='sigmoid'))\n",
        "model.add(LSTM(units = 5, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='softmax'))\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOwGFVU22OY8",
        "colab_type": "code",
        "outputId": "a80e28a7-4344-4748-8f80-14363f1dd4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 1100, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 152\n",
            "Trainable params: 152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6FNvtIJ2W9A",
        "colab_type": "code",
        "outputId": "10b95f58-f3d7-4780-c376-78e48604184d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 200, batch_size=256)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "3200/3200 [==============================] - 15s 5ms/step - loss: 7.6598 - acc: 0.3640\n",
            "Epoch 2/100\n",
            "3200/3200 [==============================] - 15s 5ms/step - loss: 3.7469 - acc: 0.3863\n",
            "Epoch 3/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 2.4010 - acc: 0.4104\n",
            "Epoch 4/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.8672 - acc: 0.4199\n",
            "Epoch 5/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.7343 - acc: 0.4410\n",
            "Epoch 6/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.6751 - acc: 0.4647\n",
            "Epoch 7/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.6230 - acc: 0.4857\n",
            "Epoch 8/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.5729 - acc: 0.5047\n",
            "Epoch 9/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.5463 - acc: 0.5105\n",
            "Epoch 10/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.5265 - acc: 0.5131\n",
            "Epoch 11/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.5110 - acc: 0.5152\n",
            "Epoch 12/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4952 - acc: 0.5165\n",
            "Epoch 13/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4765 - acc: 0.5177\n",
            "Epoch 14/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4641 - acc: 0.5188\n",
            "Epoch 15/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4547 - acc: 0.5196\n",
            "Epoch 16/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4473 - acc: 0.5201\n",
            "Epoch 17/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4405 - acc: 0.5205\n",
            "Epoch 18/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4339 - acc: 0.5207\n",
            "Epoch 19/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4275 - acc: 0.5209\n",
            "Epoch 20/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4219 - acc: 0.5210\n",
            "Epoch 21/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4143 - acc: 0.5211\n",
            "Epoch 22/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4067 - acc: 0.5211\n",
            "Epoch 23/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.4016 - acc: 0.5212\n",
            "Epoch 24/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3974 - acc: 0.5214\n",
            "Epoch 25/100\n",
            "3200/3200 [==============================] - 14s 4ms/step - loss: 1.3934 - acc: 0.5216\n",
            "Epoch 26/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3900 - acc: 0.5218\n",
            "Epoch 27/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3872 - acc: 0.5221\n",
            "Epoch 28/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3849 - acc: 0.5223\n",
            "Epoch 29/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3829 - acc: 0.5225\n",
            "Epoch 30/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3805 - acc: 0.5226\n",
            "Epoch 31/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3792 - acc: 0.5225\n",
            "Epoch 32/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3777 - acc: 0.5227\n",
            "Epoch 33/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3759 - acc: 0.5230\n",
            "Epoch 34/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3745 - acc: 0.5233\n",
            "Epoch 35/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3734 - acc: 0.5235\n",
            "Epoch 36/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3724 - acc: 0.5237\n",
            "Epoch 37/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3715 - acc: 0.5238\n",
            "Epoch 38/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3708 - acc: 0.5239\n",
            "Epoch 39/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3702 - acc: 0.5240\n",
            "Epoch 40/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3696 - acc: 0.5241\n",
            "Epoch 41/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3691 - acc: 0.5241\n",
            "Epoch 42/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3687 - acc: 0.5242\n",
            "Epoch 43/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3682 - acc: 0.5243\n",
            "Epoch 44/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3678 - acc: 0.5244\n",
            "Epoch 45/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3674 - acc: 0.5244\n",
            "Epoch 46/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3669 - acc: 0.5245\n",
            "Epoch 47/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3664 - acc: 0.5245\n",
            "Epoch 48/100\n",
            "3200/3200 [==============================] - 14s 4ms/step - loss: 1.3660 - acc: 0.5246\n",
            "Epoch 49/100\n",
            "3200/3200 [==============================] - 14s 4ms/step - loss: 1.3657 - acc: 0.5247\n",
            "Epoch 50/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3654 - acc: 0.5247\n",
            "Epoch 51/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3650 - acc: 0.5248\n",
            "Epoch 52/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3647 - acc: 0.5248\n",
            "Epoch 53/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3644 - acc: 0.5248\n",
            "Epoch 54/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3641 - acc: 0.5249\n",
            "Epoch 55/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3638 - acc: 0.5249\n",
            "Epoch 56/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3636 - acc: 0.5249\n",
            "Epoch 57/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3633 - acc: 0.5250\n",
            "Epoch 58/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3630 - acc: 0.5250\n",
            "Epoch 59/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3628 - acc: 0.5250\n",
            "Epoch 60/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3625 - acc: 0.5250\n",
            "Epoch 61/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3623 - acc: 0.5250\n",
            "Epoch 62/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3620 - acc: 0.5250\n",
            "Epoch 63/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3618 - acc: 0.5250\n",
            "Epoch 64/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3616 - acc: 0.5251\n",
            "Epoch 65/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3613 - acc: 0.5251\n",
            "Epoch 66/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3611 - acc: 0.5251\n",
            "Epoch 67/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3609 - acc: 0.5251\n",
            "Epoch 68/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3607 - acc: 0.5251\n",
            "Epoch 69/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3605 - acc: 0.5251\n",
            "Epoch 70/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3603 - acc: 0.5251\n",
            "Epoch 71/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3601 - acc: 0.5251\n",
            "Epoch 72/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3599 - acc: 0.5251\n",
            "Epoch 73/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3597 - acc: 0.5251\n",
            "Epoch 74/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3595 - acc: 0.5251\n",
            "Epoch 75/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3593 - acc: 0.5251\n",
            "Epoch 76/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3592 - acc: 0.5251\n",
            "Epoch 77/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3590 - acc: 0.5251\n",
            "Epoch 78/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3588 - acc: 0.5251\n",
            "Epoch 79/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3586 - acc: 0.5251\n",
            "Epoch 80/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3585 - acc: 0.5251\n",
            "Epoch 81/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3583 - acc: 0.5251\n",
            "Epoch 82/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3581 - acc: 0.5251\n",
            "Epoch 83/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3580 - acc: 0.5251\n",
            "Epoch 84/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3578 - acc: 0.5251\n",
            "Epoch 85/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3577 - acc: 0.5251\n",
            "Epoch 86/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3575 - acc: 0.5251\n",
            "Epoch 87/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3574 - acc: 0.5251\n",
            "Epoch 88/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3572 - acc: 0.5251\n",
            "Epoch 89/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3571 - acc: 0.5251\n",
            "Epoch 90/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3569 - acc: 0.5251\n",
            "Epoch 91/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3568 - acc: 0.5251\n",
            "Epoch 92/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3566 - acc: 0.5251\n",
            "Epoch 93/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3565 - acc: 0.5251\n",
            "Epoch 94/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3564 - acc: 0.5251\n",
            "Epoch 95/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3562 - acc: 0.5251\n",
            "Epoch 96/100\n",
            "3200/3200 [==============================] - 14s 4ms/step - loss: 1.3561 - acc: 0.5251\n",
            "Epoch 97/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3560 - acc: 0.5251\n",
            "Epoch 98/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3558 - acc: 0.5251\n",
            "Epoch 99/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3557 - acc: 0.5251\n",
            "Epoch 100/100\n",
            "3200/3200 [==============================] - 13s 4ms/step - loss: 1.3556 - acc: 0.5251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f37130f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-BqsQnr2gGc",
        "colab_type": "code",
        "outputId": "b05e277e-0506-4d51-853c-680ac01d43f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 1100, 5)\n",
            "880000\n",
            "880000\n",
            "Accuracy is: 52.81795454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX7Dfm8aYQRq",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xecnmLcI48kH",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,1)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 5, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='sigmoid'))\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-2kLCKvT48kL",
        "outputId": "87296561-fbd7-4be3-c015-081dea689f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_5 (LSTM)                (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 140\n",
            "Trainable params: 140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GtoXqLcD48kN",
        "outputId": "4811add9-4455-4bf5-c85a-c4c973389667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 150, batch_size=64)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "3200/3200 [==============================] - 64s 20ms/step - loss: 4.1542 - acc: 0.1697\n",
            "Epoch 2/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 3.5006 - acc: 0.2719\n",
            "Epoch 3/150\n",
            "3200/3200 [==============================] - 62s 20ms/step - loss: 3.1557 - acc: 0.3234\n",
            "Epoch 4/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 2.6420 - acc: 0.3716\n",
            "Epoch 5/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 2.1690 - acc: 0.4295\n",
            "Epoch 6/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.7099 - acc: 0.3732\n",
            "Epoch 7/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.5365 - acc: 0.4218\n",
            "Epoch 8/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4937 - acc: 0.4922\n",
            "Epoch 9/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.4742 - acc: 0.5138\n",
            "Epoch 10/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4610 - acc: 0.5194\n",
            "Epoch 11/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4479 - acc: 0.5214\n",
            "Epoch 12/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4307 - acc: 0.5222\n",
            "Epoch 13/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4122 - acc: 0.5225\n",
            "Epoch 14/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4017 - acc: 0.5236\n",
            "Epoch 15/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3929 - acc: 0.5245\n",
            "Epoch 16/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3858 - acc: 0.5250\n",
            "Epoch 17/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3932 - acc: 0.5256\n",
            "Epoch 18/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3749 - acc: 0.5256\n",
            "Epoch 19/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3704 - acc: 0.5258\n",
            "Epoch 20/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3668 - acc: 0.5260\n",
            "Epoch 21/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3635 - acc: 0.5262\n",
            "Epoch 22/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3606 - acc: 0.5263\n",
            "Epoch 23/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3581 - acc: 0.5263\n",
            "Epoch 24/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3562 - acc: 0.5263\n",
            "Epoch 25/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3683 - acc: 0.5263\n",
            "Epoch 26/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3514 - acc: 0.5263\n",
            "Epoch 27/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.3490 - acc: 0.5263\n",
            "Epoch 28/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3470 - acc: 0.5263\n",
            "Epoch 29/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.3459 - acc: 0.5264\n",
            "Epoch 30/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3440 - acc: 0.5264\n",
            "Epoch 31/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3407 - acc: 0.5264\n",
            "Epoch 32/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3387 - acc: 0.5264\n",
            "Epoch 33/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3378 - acc: 0.5264\n",
            "Epoch 34/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3340 - acc: 0.5264\n",
            "Epoch 35/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3320 - acc: 0.5264\n",
            "Epoch 36/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3370 - acc: 0.5264\n",
            "Epoch 37/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3328 - acc: 0.5264\n",
            "Epoch 38/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3398 - acc: 0.5264\n",
            "Epoch 39/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3978 - acc: 0.5264\n",
            "Epoch 40/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3847 - acc: 0.5264\n",
            "Epoch 41/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3607 - acc: 0.5264\n",
            "Epoch 42/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3348 - acc: 0.5264\n",
            "Epoch 43/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3281 - acc: 0.5263\n",
            "Epoch 44/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3288 - acc: 0.5263\n",
            "Epoch 45/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3245 - acc: 0.5263\n",
            "Epoch 46/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3214 - acc: 0.5263\n",
            "Epoch 47/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3179 - acc: 0.5263\n",
            "Epoch 48/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3424 - acc: 0.5263\n",
            "Epoch 49/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3910 - acc: 0.5264\n",
            "Epoch 50/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3783 - acc: 0.5263\n",
            "Epoch 51/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3572 - acc: 0.5263\n",
            "Epoch 52/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3287 - acc: 0.5263\n",
            "Epoch 53/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3211 - acc: 0.5263\n",
            "Epoch 54/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3183 - acc: 0.5263\n",
            "Epoch 55/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3153 - acc: 0.5263\n",
            "Epoch 56/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3112 - acc: 0.5263\n",
            "Epoch 57/150\n",
            "3200/3200 [==============================] - 60s 19ms/step - loss: 1.3065 - acc: 0.5263\n",
            "Epoch 58/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3004 - acc: 0.5263\n",
            "Epoch 59/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3429 - acc: 0.5263\n",
            "Epoch 60/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3081 - acc: 0.5263\n",
            "Epoch 61/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2952 - acc: 0.5263\n",
            "Epoch 62/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2939 - acc: 0.5263\n",
            "Epoch 63/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.2862 - acc: 0.5264\n",
            "Epoch 64/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2779 - acc: 0.5263\n",
            "Epoch 65/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2669 - acc: 0.5264\n",
            "Epoch 66/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.2724 - acc: 0.5263\n",
            "Epoch 67/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2511 - acc: 0.5263\n",
            "Epoch 68/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.2368 - acc: 0.5263\n",
            "Epoch 69/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.2312 - acc: 0.5263\n",
            "Epoch 70/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.2454 - acc: 0.5263\n",
            "Epoch 71/150\n",
            "3200/3200 [==============================] - 62s 20ms/step - loss: 1.2238 - acc: 0.5263\n",
            "Epoch 72/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.1756 - acc: 0.5263\n",
            "Epoch 73/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.1625 - acc: 0.5264\n",
            "Epoch 74/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.1480 - acc: 0.5264\n",
            "Epoch 75/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.1454 - acc: 0.5264\n",
            "Epoch 76/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.1467 - acc: 0.5263\n",
            "Epoch 77/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.1272 - acc: 0.5263\n",
            "Epoch 78/150\n",
            "3200/3200 [==============================] - 63s 20ms/step - loss: 1.1416 - acc: 0.5263\n",
            "Epoch 79/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4927 - acc: 0.5262\n",
            "Epoch 80/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.4395 - acc: 0.5262\n",
            "Epoch 81/150\n",
            "3200/3200 [==============================] - 62s 19ms/step - loss: 1.3946 - acc: 0.5262\n",
            "Epoch 82/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3844 - acc: 0.5262\n",
            "Epoch 83/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3693 - acc: 0.5262\n",
            "Epoch 84/150\n",
            "3200/3200 [==============================] - 61s 19ms/step - loss: 1.3382 - acc: 0.5262\n",
            "Epoch 85/150\n",
            "1920/3200 [=================>............] - ETA: 24s - loss: 1.2696 - acc: 0.5259"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-7d54c572e486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#validation_data ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lKzOPxBW48kO",
        "outputId": "a5258275-a4d0-4e76-a773-e577bea277f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 1100, 5)\n",
            "880000\n",
            "880000\n",
            "Accuracy is: 52.25863636363637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBrfgw3SYU08",
        "colab_type": "text"
      },
      "source": [
        "## LSTM-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_4beqMRU5NPd",
        "colab": {}
      },
      "source": [
        "# define the keras model\n",
        "\n",
        "batch_input_shape = (None,1100,1)  #(no_of_inputs,length_of_input_sequences,length of each vector)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='sigmoid'))\n",
        "model.add(LSTM(units = 1, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='sigmoid'))\n",
        "model.add(LSTM(units = 5, return_sequences=True, batch_input_shape=batch_input_shape,recurrent_activation='softmax'))\n",
        "\n",
        "# model.add(LSTM(4, return_sequences=True,return_state = True, input_shape=(1000 ,1)))\n",
        "# model.add(LSTM(8, return_sequences=True))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBfOArtp5NPh",
        "outputId": "8cd82d6b-0563-4729-9e6c-739b4b649750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 1100, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 1100, 1)           12        \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 1100, 5)           140       \n",
            "=================================================================\n",
            "Total params: 164\n",
            "Trainable params: 164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kad0_PmT5NPj",
        "outputId": "7bc88f74-261f-4657-8e63-71055deb9a90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 150, batch_size=64)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 0.1371 - acc: 0.5185\n",
            "Epoch 2/150\n",
            "3200/3200 [==============================] - 200s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 3/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 4/150\n",
            "3200/3200 [==============================] - 199s 62ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 5/150\n",
            "3200/3200 [==============================] - 199s 62ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 6/150\n",
            "3200/3200 [==============================] - 202s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 7/150\n",
            "3200/3200 [==============================] - 202s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 8/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 9/150\n",
            "3200/3200 [==============================] - 200s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 10/150\n",
            "3200/3200 [==============================] - 200s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 11/150\n",
            "3200/3200 [==============================] - 200s 62ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 12/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 13/150\n",
            "3200/3200 [==============================] - 202s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 14/150\n",
            "3200/3200 [==============================] - 202s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 15/150\n",
            "3200/3200 [==============================] - 207s 65ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 16/150\n",
            "3200/3200 [==============================] - 207s 65ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 17/150\n",
            "3200/3200 [==============================] - 204s 64ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 18/150\n",
            "3200/3200 [==============================] - 204s 64ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 19/150\n",
            "3200/3200 [==============================] - 204s 64ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 20/150\n",
            "3200/3200 [==============================] - 203s 64ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 21/150\n",
            "3200/3200 [==============================] - 203s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 22/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 23/150\n",
            "3200/3200 [==============================] - 202s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 24/150\n",
            "3200/3200 [==============================] - 200s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 25/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 26/150\n",
            "3200/3200 [==============================] - 201s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 27/150\n",
            "3200/3200 [==============================] - 200s 62ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 28/150\n",
            "3200/3200 [==============================] - 200s 63ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 29/150\n",
            "3200/3200 [==============================] - 207s 65ms/step - loss: 1.1921e-07 - acc: 0.5265\n",
            "Epoch 30/150\n",
            "3008/3200 [===========================>..] - ETA: 12s - loss: 1.1921e-07 - acc: 0.5265"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-7d54c572e486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m#validation_data ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5xlJb6O65NPk",
        "outputId": "b2406cdd-60e5-4a64-bfb6-fc436a811667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 1100, 5)\n",
            "880000\n",
            "880000\n",
            "Accuracy is: 52.28363636363637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHm4QT65dw14",
        "colab_type": "text"
      },
      "source": [
        "# Adding diff as a feature(same as used for LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xBpYGOHqd4X-",
        "colab": {}
      },
      "source": [
        "X = df.loc[:, ['GR']] \n",
        "y = df.loc[:, ['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9e9387f0-ad9a-45fd-f288-7811f28b68d0",
        "id": "gOOpBAqld4YC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "X=X.values\n",
        "print(X.shape)\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4400000, 1)\n",
            "[[143.51      ]\n",
            " [112.79092812]\n",
            " [123.53185623]\n",
            " ...\n",
            " [142.73450409]\n",
            " [140.03725205]\n",
            " [152.4       ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b6ea9f2b-9572-42da-bf8f-f98bbad863d6",
        "id": "Dxg3eYPud4YF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "X1 = np.delete(X, (X.shape[0]-1), axis=0)\n",
        "X1 = np.insert(X1,0,np.array([0]),axis=0)\n",
        "print(X1)\n",
        "print(X1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.        ]\n",
            " [143.51      ]\n",
            " [112.79092812]\n",
            " ...\n",
            " [142.63175614]\n",
            " [142.73450409]\n",
            " [140.03725205]]\n",
            "(4400000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7bde3319-7a58-4447-c581-6b37d882c8ff",
        "id": "xnUAVrmUd4YI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "X2 = X-X1\n",
        "print(X2)\n",
        "X2 = np.delete(X2, (0), axis=0)\n",
        "X2 = np.insert(X2,0,np.array([0]),axis=0)         #Here assigned the first value as the origin.Need to change it later.\n",
        "                                                  #Also for each well it should be different need tochange that too\n",
        "print(X2)\n",
        "print(X2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.43510000e+02]\n",
            " [-3.07190719e+01]\n",
            " [ 1.07409281e+01]\n",
            " ...\n",
            " [ 1.02747953e-01]\n",
            " [-2.69725205e+00]\n",
            " [ 1.23627480e+01]]\n",
            "[[  0.        ]\n",
            " [-30.71907188]\n",
            " [ 10.74092812]\n",
            " ...\n",
            " [  0.10274795]\n",
            " [ -2.69725205]\n",
            " [ 12.36274795]]\n",
            "(4400000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvSSoxmNd33B",
        "colab_type": "code",
        "outputId": "4db74145-5330-4b92-b58c-0758c0b42e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        " diff = pd.DataFrame(data= X2,columns=['Diff'])  # 1st row as the column names\n",
        " diff.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-30.719072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.740928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-11.839072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.920928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Diff\n",
              "0   0.000000\n",
              "1 -30.719072\n",
              "2  10.740928\n",
              "3 -11.839072\n",
              "4  11.920928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDS9DgDWd3zH",
        "colab_type": "code",
        "outputId": "761bbb51-d41d-4b4f-acf3-e2b2cb4880b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>well_id</th>\n",
              "      <th>GR</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>143.510000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>112.790928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>123.531856</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>111.692784</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>123.613712</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  well_id          GR  label\n",
              "0       0        0  143.510000      0\n",
              "1       1        0  112.790928      0\n",
              "2       2        0  123.531856      0\n",
              "3       3        0  111.692784      0\n",
              "4       4        0  123.613712      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At_Jm-t-gZIA",
        "colab_type": "code",
        "outputId": "c3dbfdae-6f89-4a81-9d83-bcc910695798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "result = pd.concat([df[['row_id','well_id','GR']], diff,df['label']], axis=1)\n",
        "result.head(2200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>well_id</th>\n",
              "      <th>GR</th>\n",
              "      <th>Diff</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>143.510000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>112.790928</td>\n",
              "      <td>-30.719072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>123.531856</td>\n",
              "      <td>10.740928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>111.692784</td>\n",
              "      <td>-11.839072</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>123.613712</td>\n",
              "      <td>11.920928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2195</th>\n",
              "      <td>1095</td>\n",
              "      <td>1</td>\n",
              "      <td>158.788972</td>\n",
              "      <td>-0.867243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2196</th>\n",
              "      <td>1096</td>\n",
              "      <td>1</td>\n",
              "      <td>139.421729</td>\n",
              "      <td>-19.367243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2197</th>\n",
              "      <td>1097</td>\n",
              "      <td>1</td>\n",
              "      <td>157.724486</td>\n",
              "      <td>18.302757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2198</th>\n",
              "      <td>1098</td>\n",
              "      <td>1</td>\n",
              "      <td>159.127243</td>\n",
              "      <td>1.402757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2199</th>\n",
              "      <td>1099</td>\n",
              "      <td>1</td>\n",
              "      <td>137.450000</td>\n",
              "      <td>-21.677243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2200 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      row_id  well_id          GR       Diff  label\n",
              "0          0        0  143.510000   0.000000      0\n",
              "1          1        0  112.790928 -30.719072      0\n",
              "2          2        0  123.531856  10.740928      0\n",
              "3          3        0  111.692784 -11.839072      0\n",
              "4          4        0  123.613712  11.920928      0\n",
              "...      ...      ...         ...        ...    ...\n",
              "2195    1095        1  158.788972  -0.867243      0\n",
              "2196    1096        1  139.421729 -19.367243      0\n",
              "2197    1097        1  157.724486  18.302757      0\n",
              "2198    1098        1  159.127243   1.402757      0\n",
              "2199    1099        1  137.450000 -21.677243      0\n",
              "\n",
              "[2200 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDBHBiSQlDpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = result[['row_id','well_id','GR','Diff']]\n",
        "y= result[['label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD7GqnwrlDgG",
        "colab_type": "code",
        "outputId": "a715c43f-2b48-46e4-b015-30dc5dbd4791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "for i in range(1,4): \n",
        "  pca = PCA(n_components = i)\n",
        "  pca.fit(X)\n",
        "  print(sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9287684605732245\n",
            "0.9990314700359433\n",
            "0.9998356045104132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hvGmAvDx5jV",
        "colab_type": "text"
      },
      "source": [
        "# Artificial Nueral Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bbfYaOth5Ab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = result[['row_id','GR','Diff']]\n",
        "y= result[['label']]\n",
        "\n",
        "y = y.values\n",
        "onehotencoder = preprocessing.OneHotEncoder(categories = [[0,1,2,3,4]])  #hot encoding y\n",
        "y_one_hot = onehotencoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "print(y_one_hot)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntB_PNlmnMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y_one_hot,test_size = 0.1)\n",
        "\n",
        "# define the keras  \n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(15, activation='relu'))\n",
        "# model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApIIdMIk2q04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lelxrMSn2i4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_tr,y_tr, epochs= 150, batch_size=256)     #validation_data ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6VaIdIQ2imu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make Predictions\n",
        "y_pred = model.predict(X_tst)\n",
        "print(y_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Converting predictions to label\n",
        "pred = []\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "      pred.append(np.argmax(y_pred[i][j]))\n",
        "\n",
        "print(len(pred))\n",
        "#Converting one hot encoded test label to label\n",
        "test = []\n",
        "for i in range(y_tst.shape[0]):\n",
        "  for j in range(y_tst.shape[1]):\n",
        "    test.append(np.argmax(y_tst[i][j]))\n",
        "\n",
        "print(len(test))\n",
        "from sklearn.metrics import accuracy_score\n",
        "a = accuracy_score(np.asarray(pred),np.asarray(test))\n",
        "print('Accuracy is:', a*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCfFY1NeVgue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}